{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import sys\n",
    "import torch \n",
    "import numpy as np\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from functools import partial\n",
    "from importlib import reload\n",
    "from transformers import (pipeline,\n",
    "                          DataCollatorWithPadding,\n",
    "                          get_scheduler)\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "# custom modules\n",
    "import utils.preprocessing as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c676e48b94414a99593cf9051f8db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 8,033,669,120 || trainable%: 0.0424\n"
     ]
    }
   ],
   "source": [
    "# options\n",
    "model_path = \"meta-llama/Meta-Llama-3-8B\"\n",
    "dataset_path = \"allenai/peS2o\"\n",
    "\n",
    "\n",
    "# for PEFT\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1\n",
    ")\n",
    "\n",
    "# load tokenizer and model\n",
    "pipeline = pipeline('text-generation', \n",
    "                    model=model_path,\n",
    "                    model_kwargs={'torch_dtype': torch.bfloat16},\n",
    "                    device_map = \"auto\"\n",
    "                    )\n",
    "\n",
    "pipeline.model = get_peft_model(pipeline.model, peft_config)\n",
    "pipeline.tokenizer.pad_token = pipeline.tokenizer.eos_token\n",
    "pipeline.tokenizer.pad_token_id = pipeline.tokenizer.eos_token_id\n",
    "pipeline.model.generation_config.pad_token_id = pipeline.tokenizer.eos_token_id\n",
    "\n",
    "pipeline.model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': 'Systems biology is the study of biological systems using a holistic approach. Systems biology is a rapidly developing field that combines experimental data, computational modeling, and mathematical analysis to understand complex biological systems. Systems biology has applications in many areas of biology, including genomics, proteomics, and metabolomics.\\nSystems biology is an interdisciplinary field that combines biology, computer science, and engineering. The goal of systems biology is to understand how biological systems work and how they respond to changes in their environment. Systems biology is a rapidly growing'}\n"
     ]
    }
   ],
   "source": [
    "# run a test prediction\n",
    "text = [\"Systems biology\"]\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    text,\n",
    "    max_new_tokens=100,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "print(outputs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDatasetDict({\n",
       "    train: IterableDataset({\n",
       "        features: ['added', 'created', 'id', 'source', 'text', 'version'],\n",
       "        n_shards: 20\n",
       "    })\n",
       "    validation: IterableDataset({\n",
       "        features: ['added', 'created', 'id', 'source', 'text', 'version'],\n",
       "        n_shards: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "raw_dataset = load_dataset(dataset_path, \"v2\", streaming=True, trust_remote_code=True)\n",
    "\n",
    "# check format of data\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: Unknown,\n",
       "    n_shards: 20\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(pp)\n",
    "# add special tokens to tokenizer\n",
    "pipeline.tokenizer.pad_token = pipeline.tokenizer.eos_token\n",
    "pipeline.model.resize_token_embeddings(len(pipeline.tokenizer))\n",
    "\n",
    "tokenize_fn = partial(pp.tokenize_data, \n",
    "                      type = \"nextchar\",\n",
    "                      pipeline_name = pipeline,\n",
    "                      max_length = 100)\n",
    "\n",
    "tokenized_dataset = raw_dataset.map(tokenize_fn,\n",
    "                                    batched=True,\n",
    "                                    remove_columns=raw_dataset['train'].column_names,)\n",
    "tokenized_dataset.with_format(\"torch\")\n",
    "\n",
    "# check tokenized dataset output\n",
    "tokenized_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=pipeline.tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(tokenized_dataset['train'],\n",
    "                              batch_size=8, \n",
    "                              collate_fn=data_collator,\n",
    "                              num_workers=20)\n",
    "\n",
    "val_dataloader = DataLoader(tokenized_dataset['validation'],\n",
    "                            batch_size=8,\n",
    "                            collate_fn=data_collator,\n",
    "                            num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 100]), 'attention_mask': torch.Size([8, 100])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect sample batch\n",
    "batch = next(iter(train_dataloader))\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1162, device='cuda:0', grad_fn=<NllLossBackward0>) torch.Size([8, 100, 128256])\n"
     ]
    }
   ],
   "source": [
    "outputs = pipeline.model(batch['input_ids'].to(accelerator.device), labels=batch['input_ids'].to(accelerator.device), attention_mask=batch['attention_mask'].to(accelerator.device))\n",
    "print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Systems biology and cancer: a review of current computational approaches for gene network generation and analysis.\n",
      "Author(s): Pagni M, Ioannidis V, Cerutti L, Zahn-Zabal M, Jongeneel CV\n",
      "Abstract Systems biology aims at understanding biological systems in terms of their components and their interactions. The focus is on the generation and analysis of large-scale data sets from different sources, including gene expression, protein-protein interaction, metabolic, and regulatory networks. This review describes the main computational\n"
     ]
    }
   ],
   "source": [
    "# run a test prediction\n",
    "text = [\"Systems biology\"]\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    text,\n",
    "    max_new_tokens=100,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "print(outputs[0][0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dataloader, val_dataloader, accelerator, pipeline):\n",
    "\n",
    "    # for distributed training\n",
    "    accelerator = Accelerator()\n",
    "\n",
    "    # options\n",
    "    num_batches = 1_000\n",
    "    num_epochs = 10\n",
    "    checkpoint_path = '../checkpoints/checkpoint_8b_{0}epochs.pt'\n",
    "    log_path = '../logs/log.csv'\n",
    "\n",
    "    # init optimizer\n",
    "    optimizer = AdamW(pipeline.model.parameters(), lr=1e-5)\n",
    "\n",
    "    # init scheduler\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=1000,\n",
    "        num_training_steps=num_epochs * num_batches,\n",
    "    )\n",
    "\n",
    "    pipeline.model, optimizer, train_dataloader, val_dataloader, lr_scheduler = accelerator.prepare(\n",
    "        pipeline.model, optimizer, train_dataloader, val_dataloader, lr_scheduler)\n",
    "\n",
    "    \n",
    "    # init parameters\n",
    "    best_val_loss = np.inf\n",
    "\n",
    "    with open(log_path, 'w') as f: \n",
    "        f.write(f'epoch,iter_num,train_loss,val_loss\\n')\n",
    "\n",
    "    # loop\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        clear_output(wait=False)\n",
    "\n",
    "        running_train_loss = 0.0\n",
    "        running_val_loss = 0.0\n",
    "\n",
    "        print(\"=====================\")\n",
    "        print(f\"Epoch {epoch + 1}\")\n",
    "        print(\"=====================\")\n",
    "\n",
    "        # loop through train data\n",
    "        print(\"Training...\")\n",
    "        with tqdm(total=num_batches) as pbar:\n",
    "            for i, (train_batch, val_batch) in enumerate(zip(train_dataloader, val_dataloader)):\n",
    "                \n",
    "                ## training\n",
    "                # set model to train mode\n",
    "                pipeline.model.train()\n",
    "\n",
    "                # grab batch and map to device\n",
    "                train_batch = {k: v.to(accelerator.device) for k, v in train_batch.items()}\n",
    "\n",
    "                # forward pass\n",
    "                outputs = pipeline.model(train_batch['input_ids'], \n",
    "                                        labels=train_batch['input_ids'],\n",
    "                                        attention_mask=train_batch['attention_mask'])\n",
    "                train_loss = outputs.loss\n",
    "\n",
    "                running_train_loss += train_loss.item()\n",
    "\n",
    "                # backward pass\n",
    "                # train_loss.backward()\n",
    "                accelerator.backward(train_loss)\n",
    "\n",
    "                # clip gradients\n",
    "                torch.nn.utils.clip_grad_norm_(pipeline.model.parameters(), 1.0)\n",
    "\n",
    "                # update optimizer, scheduler\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "\n",
    "                # zero gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                ## validation\n",
    "                # set model to eval mode\n",
    "                pipeline.model.eval()\n",
    "                # loop through val data\n",
    "                val_batch = {k: v.to(accelerator.device) for k, v in val_batch.items()}\n",
    "                with torch.no_grad():\n",
    "                    outputs = pipeline.model(val_batch['input_ids'], \n",
    "                                            labels=val_batch['input_ids'],\n",
    "                                            attention_mask=val_batch['attention_mask'])\n",
    "                    val_loss = outputs.loss\n",
    "                    running_val_loss += val_loss.item()\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                \n",
    "                print(f\"Train Batch Loss: {train_loss:.4f} | Val Batch Loss: {val_loss:.4f} | Best Val. Loss: {best_val_loss:.4f}\\r\", end=\"\")\n",
    "\n",
    "                pbar.update(1)\n",
    "                \n",
    "                # write to log\n",
    "                with open(log_path, 'a') as f: \n",
    "                    f.write(f'{epoch},{i},{train_loss},{val_loss}\\n')\n",
    "                \n",
    "                if i == num_batches:\n",
    "                    print(f\"Reached {num_batches} batches; starting next epoch...\")\n",
    "                    \n",
    "                    # break out of batching loop\n",
    "                    break\n",
    "        \n",
    "        train_loss = running_train_loss / num_batches\n",
    "        val_loss = running_val_loss / num_batches\n",
    "        train_loss = running_train_loss / num_batches\n",
    "        print(f\"Avg. Train Loss: {train_loss:.4f}, Avg. Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    print(f\"Saving model checkpoint to {checkpoint_path.format(epoch)}\")\n",
    "    # save model checkpoint\n",
    "    checkpoint = {'model': pipeline.model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'best_val_loss': best_val_loss,\n",
    "                }\n",
    "    torch.save(checkpoint, checkpoint_path.format(epoch))\n",
    "\n",
    "    print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "To launch a multi-GPU training from your notebook, the `Accelerator` should only be initialized inside your training function. Restart your notebook and make sure no cells initializes an `Accelerator`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# accelerate notebook launcher to run\u001b[39;00m\n\u001b[1;32m      2\u001b[0m args \u001b[38;5;241m=\u001b[39m (train_dataloader, val_dataloader, accelerator, pipeline)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mnotebook_launcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/DGX01/Personal/krusepi/.venv/lib/python3.9/site-packages/accelerate/launchers.py:172\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes, rdzv_backend, rdzv_endpoint, rdzv_conf, rdzv_id, max_restarts, monitor_interval, log_line_prefix_template)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspawn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProcessRaisedException\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(AcceleratorState\u001b[38;5;241m.\u001b[39m_shared_state) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo launch a multi-GPU training from your notebook, the `Accelerator` should only be initialized \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minside your training function. Restart your notebook and make sure no cells initializes an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Accelerator`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Check for specific libraries known to initialize CUDA that users constantly use\u001b[39;00m\n\u001b[1;32m    178\u001b[0m problematic_imports \u001b[38;5;241m=\u001b[39m are_libraries_initialized(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbitsandbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: To launch a multi-GPU training from your notebook, the `Accelerator` should only be initialized inside your training function. Restart your notebook and make sure no cells initializes an `Accelerator`."
     ]
    }
   ],
   "source": [
    "# accelerate notebook launcher to run\n",
    "args = (train_dataloader, val_dataloader, accelerator, pipeline)\n",
    "notebook_launcher(train_model, args = args, num_processes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Systems biology of the immune response\n",
      "\n",
      "Systems biology is a new scientific discipline that combines the study of biological networks with computational and mathematical modeling to understand how components of a biological system interact. Systems biology has been successfully applied to study signaling pathways and gene regulatory networks, and is now being applied to the study and modeling of the complex immune system. Here, we review the application of systems biology to the immune system, focusing on the analysis of gene regulatory and signaling networks, as well as on the integration of these networks with other data, such as protein-protein interactions and metabolic pathways. We also review the use of systems approaches to study the immune responses in cancer, autoimmunity, and infectious diseases. We conclude that systems biology is an important tool for studying the immune systems, and we discuss the future of this field and its impact on immunology.\n"
     ]
    }
   ],
   "source": [
    "# run a test prediction\n",
    "outputs = pipeline(\n",
    "    text,\n",
    "    max_new_tokens=1024,\n",
    "    eos_token_id=terminators,\n",
    "    no_repeat_ngram_size=3,       \n",
    "    do_sample=True, \n",
    "    top_k=100, \n",
    "    top_p=0.9,\n",
    "    temperature=0.6\n",
    ")\n",
    "print(outputs[0][0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
