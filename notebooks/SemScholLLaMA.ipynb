{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to cuda:3\n"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "import sys, os\n",
    "import torch \n",
    "import numpy as np\n",
    "import evaluate\n",
    "from trl import SFTTrainer, setup_chat_format\n",
    "from transformers import (pipeline,\n",
    "                          AutoTokenizer,\n",
    "                          AutoModelForCausalLM,\n",
    "                          DataCollatorForLanguageModeling,\n",
    "                      ``    get_scheduler)\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "# custom imports\n",
    "from utils.GetLowestGPU import GetLowestGPU\n",
    "\n",
    "device = GetLowestGPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DGX01/Personal/krusepi/.venv/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061ce5d779ae48e5a51c41ddfbfdef4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# options\n",
    "model_path = \"meta-llama/Meta-Llama-3-8B\"\n",
    "dataset_path = \"allenai/peS2o\"\n",
    "\n",
    "# load tokenizer and model\n",
    "pipeline = pipeline('text-generation', \n",
    "                    model=model_path,\n",
    "                    model_kwargs={'torch_dtype': torch.bfloat16},\n",
    "                    device_map = 'auto'\n",
    "                    )\n",
    "\n",
    "model, tokenizer = pipeline.model, pipeline.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDatasetDict({\n",
       "    train: IterableDataset({\n",
       "        features: ['added', 'created', 'id', 'source', 'text', 'version'],\n",
       "        n_shards: 20\n",
       "    })\n",
       "    validation: IterableDataset({\n",
       "        features: ['added', 'created', 'id', 'source', 'text', 'version'],\n",
       "        n_shards: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "raw_dataset = load_dataset(dataset_path, \"v2\", streaming=True, trust_remote_code=True)\n",
    "\n",
    "# check format of data\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "def preprocess_data(examples):\n",
    "    text = examples['text']\n",
    "    tokenized_data = tokenizer(text=text,\n",
    "                               text_target=text,\n",
    "                               max_length=512, \n",
    "                               return_tensors='pt',\n",
    "                               truncation=True, \n",
    "                               padding='max_length')\n",
    "    \n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDatasetDict({\n",
       "    train: IterableDataset({\n",
       "        features: Unknown,\n",
       "        n_shards: 20\n",
       "    })\n",
       "    validation: IterableDataset({\n",
       "        features: Unknown,\n",
       "        n_shards: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add special tokens to tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "tokenized_dataset = raw_dataset.map(preprocess_data, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns(['added', 'created', 'id', 'source', 'text', 'version'])\n",
    "tokenized_dataset.with_format(\"torch\")\n",
    "\n",
    "# check tokenized dataset output\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([128000,     58,  12755,   9860,  27375,    315,  37229,  15131,   6629,\n",
       "          29413,   2908,  43738,    449,    445,    946,     82,  21075,  29413,\n",
       "           2908,  30662,  44947,   6674,    198,   1271,  19874,    279,  34933,\n",
       "          15105,    323,   2875,   9860,  27375,    315,  37229,  15131,   6629,\n",
       "          29413,   2908,    320,  56493,      8,  43738,    449,    445,  17485,\n",
       "          21075,  29413,   2908,   4286,  39174,     50,    198,  26556,   6841,\n",
       "            220,   1049,     23,    323,   5936,    220,    679,     15,     11,\n",
       "          80679,   6978,    449,  44561,  11134,   1051,  12020,    449,    445,\n",
       "          17485,  21075,  29413,   2908,   1234,    802,    339,  90879,    323,\n",
       "           7946,   8272,    709,     13,   2684,   1051,    220,   3971,  25000,\n",
       "            323,    220,   1682,  28585,     11,  20330,    505,    220,   1114,\n",
       "            311,    220,   3391,   1667,    449,    459,   5578,    315,    220,\n",
       "           1682,     13,     17,   1667,     13,    578,  15319,   1051,   9057,\n",
       "            555,  10775,    304,    220,   5495,   5157,     11,   9629,  11677,\n",
       "            304,    220,    975,   5157,     11,    323,  43100,   1082,    304,\n",
       "            220,     18,   5157,     13,   2684,   1051,    220,   3391,   2163,\n",
       "          31624,    323,    220,   1806,   1314,  31624,     13,    578,   8624,\n",
       "           8250,  41829,    505,    220,    605,   2919,    311,    220,    806,\n",
       "           4038,     13,    578,  37229,  27580,   1296,     11,    445,    613,\n",
       "           1543,   1296,     11,    323,  27137,   6541,   1296,    369,    682,\n",
       "           5157,   1051,  22359,    439,   6928,     13,    578,    864,  43719,\n",
       "          16333,    939,    337,     76,   5573,    574,    220,   2131,     13,\n",
       "             19,  52715,    220,     20,     13,     22,     11,    358,   2026,\n",
       "            526,   5573,    574,    220,   2166,     13,     18,  52715,    220,\n",
       "             21,     13,     17,     11,    323,  86178,   5573,    574,    220,\n",
       "           4370,     13,     23,  52715,    220,     22,     13,     19,     26,\n",
       "            323,    279,   7327,  98312,  45565,  10554,    320,  29661,   5744,\n",
       "              8,   5573,    574,   4827,   1109,   4725,   2237,    304,    682,\n",
       "           5157,     13,   4761,  37526,  22760,    278,  52460,   8710,  44561,\n",
       "          11134,    304,    682,   5157,     13,   1838,   3421,  44561,    323,\n",
       "           6925,    869,   2411,   1051,  34683,   2391,  15173,   4286,  86728,\n",
       "            198,   2460,   3709,   6948,  62320,    555,   1176,  14944,   2085,\n",
       "          86919,    315,  19405,    477,   5655,  11457,    788,  84664,     65,\n",
       "          10934,     13,   2052,   6978,   1051,   8272,    709,    220,     22,\n",
       "            311,    220,   1187,   4038,    449,    459,   5578,    315,    220,\n",
       "            845,     13,     23,   4038,     13,   2684,   1051,    220,     18,\n",
       "           5157,    315,  46022,  14675,   9017,   5103,  10020,  83619,  17685,\n",
       "             11,    220,     17,   5157,    315,  46050,   6147,    259,    581,\n",
       "            532,  22733,     11,    323,    220,     16,   1162,    315,  22095,\n",
       "           9070,  20893,     11,    323,    814,   1051,  64688,   1306,  12104,\n",
       "          13795,   6514,     13,   2360,    445,  17485,  21075,  29413,   2908,\n",
       "          89869,    323,  10496,  16178,  63412,  10222,   2391,   1833,   5352,\n",
       "             13,   2468,   1566,   1833,   5352,     11,    279,   3135,    315,\n",
       "          37229,  27580,   1296,     11,    445,    613,   1543,   1296,     11,\n",
       "            323,  27137,   6541,   1296,   1051,   6928,    304,    220,     17,\n",
       "             11,    220,     18,     11,    323,    220,     18,   6978,     11,\n",
       "          15947,     13,   2684,   1051,   5199,  12062,    304,  16333,    939,\n",
       "            337,     76,     11,    358,   2026,    526,     11,    323,  86178,\n",
       "          12483,    315,  11754,  31624,   1990,    864,   9446,    323,    220,\n",
       "             21,   5672,   1772,   3376,   8046,     11,   1566,   1833,   5352,\n",
       "             11,  15947,    320,     47,    366,    220,     15,     13,   2304,\n",
       "            570,    578,   4725,   4478,    315,  48491,   5744,   5573,   1051,\n",
       "            220,   3391,     13,   2075,      4,    320,   1758,     14,   1490,\n",
       "              8,    323,    220,   3534,     13,   1135,      4,    320,   2495,\n",
       "             14,   1490,      8,    520,    220,     21,   5672,   1772,   3376,\n",
       "           8046,    323,   1566,   1833,   5352,     11,  15947,   4286,   5910,\n",
       "          99769,    198,    791,   2145,   1030,  63064,   6012,    315]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'labels': tensor([128000,     58,  12755,   9860,  27375,    315,  37229,  15131,   6629,\n",
       "          29413,   2908,  43738,    449,    445,    946,     82,  21075,  29413,\n",
       "           2908,  30662,  44947,   6674,    198,   1271,  19874,    279,  34933,\n",
       "          15105,    323,   2875,   9860,  27375,    315,  37229,  15131,   6629,\n",
       "          29413,   2908,    320,  56493,      8,  43738,    449,    445,  17485,\n",
       "          21075,  29413,   2908,   4286,  39174,     50,    198,  26556,   6841,\n",
       "            220,   1049,     23,    323,   5936,    220,    679,     15,     11,\n",
       "          80679,   6978,    449,  44561,  11134,   1051,  12020,    449,    445,\n",
       "          17485,  21075,  29413,   2908,   1234,    802,    339,  90879,    323,\n",
       "           7946,   8272,    709,     13,   2684,   1051,    220,   3971,  25000,\n",
       "            323,    220,   1682,  28585,     11,  20330,    505,    220,   1114,\n",
       "            311,    220,   3391,   1667,    449,    459,   5578,    315,    220,\n",
       "           1682,     13,     17,   1667,     13,    578,  15319,   1051,   9057,\n",
       "            555,  10775,    304,    220,   5495,   5157,     11,   9629,  11677,\n",
       "            304,    220,    975,   5157,     11,    323,  43100,   1082,    304,\n",
       "            220,     18,   5157,     13,   2684,   1051,    220,   3391,   2163,\n",
       "          31624,    323,    220,   1806,   1314,  31624,     13,    578,   8624,\n",
       "           8250,  41829,    505,    220,    605,   2919,    311,    220,    806,\n",
       "           4038,     13,    578,  37229,  27580,   1296,     11,    445,    613,\n",
       "           1543,   1296,     11,    323,  27137,   6541,   1296,    369,    682,\n",
       "           5157,   1051,  22359,    439,   6928,     13,    578,    864,  43719,\n",
       "          16333,    939,    337,     76,   5573,    574,    220,   2131,     13,\n",
       "             19,  52715,    220,     20,     13,     22,     11,    358,   2026,\n",
       "            526,   5573,    574,    220,   2166,     13,     18,  52715,    220,\n",
       "             21,     13,     17,     11,    323,  86178,   5573,    574,    220,\n",
       "           4370,     13,     23,  52715,    220,     22,     13,     19,     26,\n",
       "            323,    279,   7327,  98312,  45565,  10554,    320,  29661,   5744,\n",
       "              8,   5573,    574,   4827,   1109,   4725,   2237,    304,    682,\n",
       "           5157,     13,   4761,  37526,  22760,    278,  52460,   8710,  44561,\n",
       "          11134,    304,    682,   5157,     13,   1838,   3421,  44561,    323,\n",
       "           6925,    869,   2411,   1051,  34683,   2391,  15173,   4286,  86728,\n",
       "            198,   2460,   3709,   6948,  62320,    555,   1176,  14944,   2085,\n",
       "          86919,    315,  19405,    477,   5655,  11457,    788,  84664,     65,\n",
       "          10934,     13,   2052,   6978,   1051,   8272,    709,    220,     22,\n",
       "            311,    220,   1187,   4038,    449,    459,   5578,    315,    220,\n",
       "            845,     13,     23,   4038,     13,   2684,   1051,    220,     18,\n",
       "           5157,    315,  46022,  14675,   9017,   5103,  10020,  83619,  17685,\n",
       "             11,    220,     17,   5157,    315,  46050,   6147,    259,    581,\n",
       "            532,  22733,     11,    323,    220,     16,   1162,    315,  22095,\n",
       "           9070,  20893,     11,    323,    814,   1051,  64688,   1306,  12104,\n",
       "          13795,   6514,     13,   2360,    445,  17485,  21075,  29413,   2908,\n",
       "          89869,    323,  10496,  16178,  63412,  10222,   2391,   1833,   5352,\n",
       "             13,   2468,   1566,   1833,   5352,     11,    279,   3135,    315,\n",
       "          37229,  27580,   1296,     11,    445,    613,   1543,   1296,     11,\n",
       "            323,  27137,   6541,   1296,   1051,   6928,    304,    220,     17,\n",
       "             11,    220,     18,     11,    323,    220,     18,   6978,     11,\n",
       "          15947,     13,   2684,   1051,   5199,  12062,    304,  16333,    939,\n",
       "            337,     76,     11,    358,   2026,    526,     11,    323,  86178,\n",
       "          12483,    315,  11754,  31624,   1990,    864,   9446,    323,    220,\n",
       "             21,   5672,   1772,   3376,   8046,     11,   1566,   1833,   5352,\n",
       "             11,  15947,    320,     47,    366,    220,     15,     13,   2304,\n",
       "            570,    578,   4725,   4478,    315,  48491,   5744,   5573,   1051,\n",
       "            220,   3391,     13,   2075,      4,    320,   1758,     14,   1490,\n",
       "              8,    323,    220,   3534,     13,   1135,      4,    320,   2495,\n",
       "             14,   1490,      8,    520,    220,     21,   5672,   1772,   3376,\n",
       "           8046,    323,   1566,   1833,   5352,     11,  15947,   4286,   5910,\n",
       "          99769,    198,    791,   2145,   1030,  63064,   6012,    315])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(tokenized_dataset['train']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate data collator\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "train_dataloader = DataLoader(tokenized_dataset['train'],\n",
    "                              batch_size=8, \n",
    "                              collate_fn=data_collator,\n",
    "                              num_workers=20)\n",
    "\n",
    "val_dataloader = DataLoader(tokenized_dataset['validation'],\n",
    "                            batch_size=8,\n",
    "                            collate_fn=data_collator,\n",
    "                            num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 512]),\n",
       " 'attention_mask': torch.Size([8, 512]),\n",
       " 'labels': torch.Size([8, 512])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect sample batch\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8214, grad_fn=<ToCopyBackward0>) torch.Size([8, 512, 128256])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**batch)\n",
    "print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "# initialize optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# and scheduler\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "=====================\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d7ae7265614f36a1191ca1178d0276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DGX01/Personal/krusepi/.venv/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "# eval loop\n",
    "\n",
    "# define metrics\n",
    "# metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "\n",
    "# loop through epochs\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}\\n=====================\")\n",
    "\n",
    "    # set model to train mode\n",
    "    model.train()\n",
    "\n",
    "    # initialize train loss, val loss\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    # loop through train data\n",
    "    print(\"Training...\")\n",
    "    for batch in train_dataloader:\n",
    "\n",
    "        # grab batch and map to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        # update scheduler\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    train_loss = train_loss / (len(train_dataloader) / batch_size)\n",
    "\n",
    "    # set to eval mode\n",
    "    model.eval()\n",
    "    print(\"Validating...\")\n",
    "    for batch in val_dataloader:\n",
    "\n",
    "        # get batch\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # forward pass\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        # get loss\n",
    "        loss = outputs.loss\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        # get logits, predictions\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        # metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "\n",
    "    val_loss = val_loss / (len(val_dataloader) / batch_size)\n",
    "\n",
    "    print(f\"Avg. Train Loss: {train_loss}, Avg. Val Loss: {val_loss}\")\n",
    "    # print(\"Evaluation metrics:\", metric.compute())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': ' \\n \\n           \\n   \\n          \\n                                                          -    —    -  —    —    —  —  — -•  — - ————————————————————————————————————————————————————————————————————————~———~———~—————————~————~—————————————————————————————————————————————~——-——'}\n"
     ]
    }
   ],
   "source": [
    "# run a test prediction\n",
    "messages = [\n",
    "\n",
    "]\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
