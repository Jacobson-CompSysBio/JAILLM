{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import sys\n",
    "import torch \n",
    "import numpy as np\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from functools import partial\n",
    "from importlib import reload\n",
    "from transformers import pipeline as pipe\n",
    "from transformers import (\n",
    "                          DataCollatorWithPadding,\n",
    "                          get_scheduler)\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "# custom modules\n",
    "import utils.preprocessing as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "model_path = \"meta-llama/Meta-Llama-3-8B\"\n",
    "dataset_path = \"allenai/peS2o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_path, dataset_path):\n",
    "\n",
    "    # for distributed training\n",
    "    accelerator = Accelerator()\n",
    "\n",
    "    # load dataset\n",
    "    raw_dataset = load_dataset(dataset_path, \"v2\", streaming=True, trust_remote_code=True)\n",
    "\n",
    "    ## MODEL LOADING\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1\n",
    "    )\n",
    "\n",
    "    # load tokenizer and model\n",
    "    pipeline = pipe('text-generation', \n",
    "                        model=model_path,\n",
    "                        model_kwargs={'torch_dtype': torch.bfloat16},\n",
    "                        device_map = accelerator.device \n",
    "                        )\n",
    "\n",
    "    pipeline.model = get_peft_model(pipeline.model, peft_config)\n",
    "    pipeline.tokenizer.pad_token = pipeline.tokenizer.eos_token\n",
    "    pipeline.tokenizer.pad_token_id = pipeline.tokenizer.eos_token_id\n",
    "    pipeline.model.generation_config.pad_token_id = pipeline.tokenizer.eos_token_id\n",
    "\n",
    "\n",
    "    ## PREPROCESSING\n",
    "    # add special tokens to tokenizer\n",
    "    pipeline.tokenizer.pad_token = pipeline.tokenizer.eos_token\n",
    "    pipeline.model.resize_token_embeddings(len(pipeline.tokenizer))\n",
    "\n",
    "    tokenize_fn = partial(pp.tokenize_data, \n",
    "                        type = \"nextchar\",\n",
    "                        pipeline_name = pipeline,\n",
    "                        max_length = 100)\n",
    "\n",
    "    tokenized_dataset = raw_dataset.map(tokenize_fn,\n",
    "                                        batched=True,\n",
    "                                        remove_columns=raw_dataset['train'].column_names,)\n",
    "    tokenized_dataset.with_format(\"torch\")\n",
    "\n",
    "    # instantiate data collator\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=pipeline.tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(tokenized_dataset['train'],\n",
    "                                batch_size=8, \n",
    "                                collate_fn=data_collator,\n",
    "                                num_workers=20)\n",
    "\n",
    "    val_dataloader = DataLoader(tokenized_dataset['validation'],\n",
    "                            batch_size=8,\n",
    "                            collate_fn=data_collator,\n",
    "                            num_workers=2)\n",
    "    \n",
    "    ## TRAINING\n",
    "\n",
    "    # options\n",
    "    num_batches = 100\n",
    "    num_epochs = 1\n",
    "    checkpoint_path = '../checkpoints/checkpoint_8b_{0}epochs.pt'\n",
    "    log_path = '../logs/log.csv'\n",
    "\n",
    "    # init optimizer\n",
    "    optimizer = AdamW(pipeline.model.parameters(), lr=1e-5)\n",
    "\n",
    "    # init scheduler\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=1000,\n",
    "        num_training_steps=num_epochs * num_batches,\n",
    "    )\n",
    "\n",
    "    pipeline.model, optimizer, train_dataloader, val_dataloader, lr_scheduler = accelerator.prepare(\n",
    "        pipeline.model, optimizer, train_dataloader, val_dataloader, lr_scheduler)\n",
    "\n",
    "    \n",
    "    # init parameters\n",
    "    best_val_loss = np.inf\n",
    "\n",
    "    with open(log_path, 'w') as f: \n",
    "        f.write(f'epoch,iter_num,train_loss,val_loss\\n')\n",
    "\n",
    "    # loop\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        clear_output(wait=False)\n",
    "\n",
    "        running_train_loss = 0.0\n",
    "        running_val_loss = 0.0\n",
    "\n",
    "        print(\"=====================\")\n",
    "        print(f\"Epoch {epoch + 1}\")\n",
    "        print(\"=====================\")\n",
    "\n",
    "        # loop through train data\n",
    "        print(\"Training...\")\n",
    "        with tqdm(total=num_batches) as pbar:\n",
    "            for i, (train_batch, val_batch) in enumerate(zip(train_dataloader, val_dataloader)):\n",
    "                \n",
    "                ## training\n",
    "                # set model to train mode\n",
    "                pipeline.model.train()\n",
    "\n",
    "                # grab batch and map to device\n",
    "                train_batch = {k: v.to(accelerator.device) for k, v in train_batch.items()}\n",
    "\n",
    "                # forward pass\n",
    "                outputs = pipeline.model(train_batch['input_ids'], \n",
    "                                        labels=train_batch['input_ids'],\n",
    "                                        attention_mask=train_batch['attention_mask'])\n",
    "                train_loss = outputs.loss\n",
    "\n",
    "                running_train_loss += train_loss.item()\n",
    "\n",
    "                # backward pass\n",
    "                # train_loss.backward()\n",
    "                accelerator.backward(train_loss)\n",
    "\n",
    "                # clip gradients\n",
    "                torch.nn.utils.clip_grad_norm_(pipeline.model.parameters(), 1.0)\n",
    "\n",
    "                # update optimizer, scheduler\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "\n",
    "                # zero gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                ## validation\n",
    "                # set model to eval mode\n",
    "                pipeline.model.eval()\n",
    "                # loop through val data\n",
    "                val_batch = {k: v.to(accelerator.device) for k, v in val_batch.items()}\n",
    "                with torch.no_grad():\n",
    "                    outputs = pipeline.model(val_batch['input_ids'], \n",
    "                                            labels=val_batch['input_ids'],\n",
    "                                            attention_mask=val_batch['attention_mask'])\n",
    "                    val_loss = outputs.loss\n",
    "                    running_val_loss += val_loss.item()\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                \n",
    "                print(f\"Train Batch Loss: {train_loss:.4f} | Val Batch Loss: {val_loss:.4f} | Best Val. Loss: {best_val_loss:.4f}\\r\", end=\"\")\n",
    "\n",
    "                pbar.update(1)\n",
    "                \n",
    "                # write to log\n",
    "                with open(log_path, 'a') as f: \n",
    "                    f.write(f'{epoch},{i},{train_loss},{val_loss}\\n')\n",
    "                \n",
    "                if i == num_batches:\n",
    "                    print(f\"Reached {num_batches} batches; starting next epoch...\")\n",
    "                    \n",
    "                    # break out of batching loop\n",
    "                    break\n",
    "        \n",
    "        train_loss = running_train_loss / num_batches\n",
    "        val_loss = running_val_loss / num_batches\n",
    "        train_loss = running_train_loss / num_batches\n",
    "        print(f\"Avg. Train Loss: {train_loss:.4f}, Avg. Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    print(f\"Saving model checkpoint to {checkpoint_path.format(epoch)}\")\n",
    "    # save model checkpoint\n",
    "    checkpoint = {'model': pipeline.model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'best_val_loss': best_val_loss,\n",
    "                }\n",
    "    torch.save(checkpoint, checkpoint_path.format(epoch))\n",
    "\n",
    "    print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "Epoch 1\n",
      "=====================\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcffb387bd14e03a070d58e93fd4f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "Epoch 1\n",
      "=====================\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e9192ec6b842b1a37eb578c4ae537f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 100 batches; starting next epoch...2.3064 | Best Val. Loss: 1.8702\n",
      "Reached 100 batches; starting next epoch...\n",
      "Avg. Train Loss: 2.3372, Avg. Val Loss: 2.3134\n",
      "Saving model checkpoint to ../checkpoints/checkpoint_8b_0epochs.pt\n",
      "Avg. Train Loss: 2.3784, Avg. Val Loss: 2.4761\n",
      "Saving model checkpoint to ../checkpoints/checkpoint_8b_0epochs.pt\n",
      "Training Complete!Training Complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accelerate notebook launcher to run\n",
    "args = (model_path, dataset_path)\n",
    "notebook_launcher(train_model, args = args, num_processes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a test prediction\n",
    "outputs = pipe(\n",
    "    text,\n",
    "    max_new_tokens=1024,\n",
    "    eos_token_id=terminators,\n",
    "    no_repeat_ngram_size=3,       \n",
    "    do_sample=True, \n",
    "    top_k=100, \n",
    "    top_p=0.9,\n",
    "    temperature=0.6\n",
    ")\n",
    "print(outputs[0][0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
