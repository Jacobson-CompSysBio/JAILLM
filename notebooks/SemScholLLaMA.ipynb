{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-11 09:48:45,745] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n",
      "Device set to cuda:1\n"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "import sys, os\n",
    "import torch \n",
    "import numpy as np\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "from trl import SFTTrainer, setup_chat_format\n",
    "from transformers import (pipeline,\n",
    "                          AutoTokenizer,\n",
    "                          AutoModelForCausalLM,\n",
    "                          DataCollatorForLanguageModeling,\n",
    "                          DataCollatorWithPadding,\n",
    "                          get_scheduler)\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "# custom imports\n",
    "from utils.GetLowestGPU import GetLowestGPU\n",
    "\n",
    "device = GetLowestGPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b71a55588184087aecf20c9f56bd5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 8,033,669,120 || trainable%: 0.0424\n"
     ]
    }
   ],
   "source": [
    "# options\n",
    "model_path = \"meta-llama/Meta-Llama-3-8B\"\n",
    "dataset_path = \"allenai/peS2o\"\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1\n",
    ")\n",
    "\n",
    "# load tokenizer and model\n",
    "pipeline = pipeline('text-generation', \n",
    "                    model=model_path,\n",
    "                    model_kwargs={'torch_dtype': torch.bfloat16},\n",
    "                    device_map = 'auto'\n",
    "                    )\n",
    "\n",
    "pipeline.model = get_peft_model(pipeline.model, peft_config)\n",
    "pipeline.tokenizer.pad_token = pipeline.tokenizer.eos_token\n",
    "pipeline.model.generation_config.pad_token_id = pipeline.tokenizer.eos_token_id\n",
    "\n",
    "pipeline.model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDatasetDict({\n",
       "    train: IterableDataset({\n",
       "        features: ['added', 'created', 'id', 'source', 'text', 'version'],\n",
       "        n_shards: 20\n",
       "    })\n",
       "    validation: IterableDataset({\n",
       "        features: ['added', 'created', 'id', 'source', 'text', 'version'],\n",
       "        n_shards: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "raw_dataset = load_dataset(dataset_path, \"v2\", streaming=True, trust_remote_code=True)\n",
    "\n",
    "# check format of data\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "def preprocess_data(examples):\n",
    "    tokenized_data = pipeline.tokenizer(text=examples['text'],\n",
    "                               padding='max_length', \n",
    "                               truncation=True, \n",
    "                               max_length=128)\n",
    "    \n",
    "    labels = tokenized_data['input_ids'].copy()\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i][-1] != pipeline.tokenizer.pad_token_id:\n",
    "            labels[i] = labels[i][1:] + [pipeline.tokenizer.pad_token_id]\n",
    "        else:\n",
    "            labels[i] = labels[i][1:] + [-100]\n",
    "\n",
    "    labels = [[-100 if x == pipeline.tokenizer.pad_token_id else x for x in y] for y in labels]\n",
    "    tokenized_data['labels'] = labels\n",
    "    \n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDatasetDict({\n",
       "    train: IterableDataset({\n",
       "        features: Unknown,\n",
       "        n_shards: 20\n",
       "    })\n",
       "    validation: IterableDataset({\n",
       "        features: Unknown,\n",
       "        n_shards: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add special tokens to tokenizer\n",
    "pipeline.tokenizer.pad_token = pipeline.tokenizer.eos_token\n",
    "pipeline.model.resize_token_embeddings(len(pipeline.tokenizer))\n",
    "\n",
    "tokenized_dataset = raw_dataset.map(preprocess_data,\n",
    "                                    batched=True,\n",
    "                                    remove_columns=raw_dataset['train'].column_names,)\n",
    "tokenized_dataset.with_format(\"torch\")\n",
    "\n",
    "# check tokenized dataset output\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=pipeline.tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(tokenized_dataset['train'],\n",
    "                              batch_size=8, \n",
    "                              collate_fn=data_collator,\n",
    "                              num_workers=20)\n",
    "\n",
    "val_dataloader = DataLoader(tokenized_dataset['validation'],\n",
    "                            batch_size=8,\n",
    "                            collate_fn=data_collator,\n",
    "                            num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 128]),\n",
       " 'attention_mask': torch.Size([8, 128]),\n",
       " 'labels': torch.Size([8, 128])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect sample batch\n",
    "batch = next(iter(train_dataloader))\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.3959, grad_fn=<ToCopyBackward0>) torch.Size([8, 128, 128256])\n"
     ]
    }
   ],
   "source": [
    "outputs = pipeline.model(**batch)\n",
    "print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network biology is the study of biological systems and processes using a network perspective. The approach is to treat a biological system as a network of interacting molecules, cells, or other entities. Network biology has been used to study a wide range of biological processes, including gene regulation, protein-protein interactions, and metabolic pathways.\n",
      "What are the main principles of network biology?\n",
      "The main principles of network biology are that biological systems can be modeled as networks of interacting molecules, cells, or other entities; that these networks can be used to understand the behavior of biological systems; and that the study of these networks can lead to new insights into biological processes.\n",
      "How does network biology differ from traditional biology?\n",
      "Network biology is a relatively new field that takes a different approach to studying biology than traditional biology. Traditional biology is focused on understanding the individual components of a biological system, while network biology is focused on understanding the interactions between these components. This allows network biology to study the system as a whole, rather than just its individual parts.\n",
      "What are some of the challenges facing network biology?\n",
      "Network biology is a relatively new field that is still in its early stages of development. As such, there are still many challenges that need to be overcome before it can be widely adopted as a tool for studying biology. Some of the challenges facing\n"
     ]
    }
   ],
   "source": [
    "# run a test prediction\n",
    "text = [\"Network biology is\"]\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    text,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "#     pipeline.model, optimizer, train_dataloader, lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "Epoch 1\n",
      "=====================\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ec1a87e1eb4aa3bfa4ea386d91c91a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DGX01/Personal/krusepi/.venv/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000 of 10000; Printing Example Response... | Best Val. Loss: 0.7985316\n",
      "Network biology is the analysis of biological systems using network theory the study of interactions among a set of objects such as genes proteins or the study of the network of connections among proteins in a cell is an example of systems biology network biology is the application of graph theory a sub branch of mathematics to the study of biological systems. The biological network is a complex system that can be studied using the tools of network theory in this review we first present the basic concepts of network theory then we introduce the application of network theory in biological systems including biological networks the network of\n",
      "Batch 2000 of 10000; Printing Example Response... | Best Val. Loss: 0.1987\n",
      "Network biology is the study of biological systems from the perspective of complex systems and networks. In contrast to the traditional reductionist approach, systems biology aims to study the system as a whole and to understand the emergent properties of the system from the interactions of its components. Network biology provides a framework for systems biology, where the components of the system are represented as nodes in a network and the interactions between the components are represented as edges in the network. The aim of network biology is to identify the key nodes and edges in the network that are responsible for the emergent properties of the system.\n",
      "\n",
      "### Application in biology\n",
      "\n",
      "Biology is a complex system that can be studied from the perspective of network biology. In particular, network biology can be used to study the interactions between genes, proteins, and other biomolecules in a cell or organism. For example, the interactions between genes can be represented as a network, where the genes are nodes and the interactions between the genes are edges. This network can be used to identify the key genes that are responsible for the emergent properties of the cell or organism. Similarly, the interactions between proteins can be represented as a network, where the proteins are nodes and the interactions between the proteins are edges. This network can be used to identify the key proteins that are responsible for\n",
      "Batch 3000 of 10000; Printing Example Response... | Best Val. Loss: 0.1404\n",
      "Network biology is the application of network theory to biologicals, specifically, the structure and behavior of biologicals such asregulatory networks, protein, and metabolic networks. It is an interdisciplinary science that combines methods from computer, mathematics and physics with concepts and findings from molecular biology, genetics, and biochemistry. Network biology has been used to study many biologicals including cell, developmental, andimmunology.\n",
      "Network biology is the application of network theory to biologicals, specifically, the structure and behavior of biologicals such asregulatory networks, protein, and metabolic networks. It is an interdisciplinary science that combines methods from computer, mathematics and physics with concepts and findings from molecular biology, genetics, and biochemistry. Network biology has been used to study many biologicals including cell, developmental, andimmunology.\n",
      "Network biology is the application of network theory to biologicals, specifically, the structure and behavior of biologicals such asregulatory networks, protein, and metabolic networks. It is an interdisciplinary science that combines methods from computer, mathematics and physics with concepts and findings from molecular biology, genetics, and biochemistry. Network biology has been used to study many biologicals including cell, developmental, andimmunology.\n",
      "Network biology is the application of network theory to biologicals, specifically, the structure\n",
      "Batch 4000 of 10000; Printing Example Response... | Best Val. Loss: 0.1366\n",
      "Network biology is the study of biological systems using methods originally developed in graph theory and more recently in network theory and applied mathematics. In contrast to studying systems in which elements react independently, networks take into account that there are, in fact, relationships between the elements of a system and that these relationships can be studied, modeled, and used. The elements, relationships, and their properties and quantities are represented with either numerical values or visual graphs, hence the name network analysis.\n",
      "\n",
      "## Definition\n",
      "\n",
      "Network biology is the study of biological systems using methods originally developed in graph theory and more recently in network theory and applied mathematics. In contrast to studying systems in which elements react independently, networks take into account that there are, in fact, relationships between the elements of a system and that these relationships can be studied, modeled, and used. The elements, relationships, and their properties and quantities are represented with either numerical values or visual graphs, hence the name network analysis.\n",
      "\n",
      "## History\n",
      "\n",
      "Network biology was first proposed by Albert-László Barabási in 2001. Barabási's idea was to use the methods of graph theory to study biological systems. The method was first used to study protein-protein interactions. In 2004 Barabási and his co-authors published a paper\n",
      "Train Batch Loss: 0.1369 | Val Batch Loss: 0.1364 | Best Val. Loss: 0.1362\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m running_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# backward pass\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[43mtrain_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# accelerator.backward(loss)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# clip gradients\u001b[39;00m\n\u001b[1;32m     59\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(pipeline\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m/mnt/DGX01/Personal/krusepi/.venv/lib/python3.8/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/DGX01/Personal/krusepi/.venv/lib/python3.8/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/DGX01/Personal/krusepi/.venv/lib/python3.8/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# options\n",
    "num_batches = 10_000\n",
    "num_epochs = 1\n",
    "best_val_loss = np.inf\n",
    "checkpoint_path = '../checkpoints/checkpoint_{0}.pt'\n",
    "log_path = '../logs/log.csv'\n",
    "\n",
    "# init optimizer\n",
    "optimizer = AdamW(pipeline.model.parameters(), lr=1e-5)\n",
    "\n",
    "# init scheduler\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=1000,\n",
    "    num_training_steps=num_epochs * num_batches,\n",
    ")\n",
    "\n",
    "with open(log_path, 'w') as f: \n",
    "    f.write(f'epoch,iter_num,train_loss,val_loss\\n')\n",
    "\n",
    "# loop\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    print(\"=====================\")\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    print(\"=====================\")\n",
    "\n",
    "    # initialize train loss, val loss\n",
    "    running_train_loss = 0.0\n",
    "    running_val_loss = 0.0\n",
    "\n",
    "    # loop through train data\n",
    "    print(\"Training...\")\n",
    "    i = 0\n",
    "    with tqdm(total=num_batches) as pbar:\n",
    "        for train_batch, val_batch in zip(train_dataloader, val_dataloader):\n",
    "            \n",
    "            ## training\n",
    "            # set model to train mode\n",
    "            pipeline.model.train()\n",
    "\n",
    "            # grab batch and map to device\n",
    "            train_batch = {k: v.to(device) for k, v in train_batch.items()}\n",
    "\n",
    "            # forward pass\n",
    "            outputs = pipeline.model(**batch)\n",
    "            train_loss = outputs.loss\n",
    "\n",
    "            running_train_loss += train_loss.item()\n",
    "\n",
    "            # backward pass\n",
    "            train_loss.backward()\n",
    "            # accelerator.backward(loss)\n",
    "\n",
    "            # clip gradients\n",
    "            torch.nn.utils.clip_grad_norm_(pipeline.model.parameters(), 1.0)\n",
    "\n",
    "            # update optimizer, scheduler\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            # zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            ## validation\n",
    "            # set model to eval mode\n",
    "            pipeline.model.eval()\n",
    "            # loop through val data\n",
    "            val_batch = {k: v.to(device) for k, v in val_batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = pipeline.model(**batch)\n",
    "                val_loss = outputs.loss\n",
    "                running_val_loss += val_loss.item()\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "            \n",
    "            print(f\"Train Batch Loss: {train_loss:.4f} | Val Batch Loss: {val_loss:.4f} | Best Val. Loss: {best_val_loss:.4f}\\r\", end=\"\")\n",
    "\n",
    "            i += 1\n",
    "            pbar.update(1)\n",
    "            if i % 1000 == 0:\n",
    "\n",
    "                # # save model checkpoint\n",
    "                # checkpoint = {\n",
    "                #     'model': pipeline.model.state_dict(),\n",
    "                #     'optimizer': optimizer.state_dict(),\n",
    "                #     'epoch': epoch,\n",
    "                #     'iter_num': i,``\n",
    "                #     'best_val_loss': best_val_loss,\n",
    "                # }\n",
    "                # torch.save(checkpoint, checkpoint_path.format(i))\n",
    "\n",
    "                # print example output\n",
    "                print(f\"Batch {i} of {num_batches}; Printing Example Response...\")\n",
    "                print(pipeline(text,\n",
    "                               max_new_tokens=256,\n",
    "                               eos_token_id=terminators,\n",
    "                               do_sample=True,\n",
    "                               temperature=0.6,\n",
    "                               top_p=0.9)[0][0]['generated_text'])\n",
    "\n",
    "            # write to log\n",
    "            with open(log_path, 'a') as f: \n",
    "                f.write(f'{epoch},{i},{train_loss},{val_loss}\\n')\n",
    "            \n",
    "            if i == num_batches:\n",
    "                print(f\"Reached {num_batches} batches; breaking...\")\n",
    "                break\n",
    "    \n",
    "    train_loss = running_train_loss / num_batches\n",
    "    val_loss = running_val_loss / num_batches\n",
    "\n",
    "    print(\"Epoch Complete; Printing example response...\")\n",
    "    print(pipeline(text, max_length=100, truncation=True))\n",
    "\n",
    "    train_loss = running_train_loss / len(train_dataloader)\n",
    "    print(f\"Avg. Train Loss: {train_loss:.4f}, Avg. Val Loss: {val_loss:.4f}\")\n",
    "    # print(\"Evaluation metrics:\", metric.compute())\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network biology is an interdisciplinary field that investigates complex biological. A systematic approach to the study of biological systems. Network theory. Biological network modeling is an important tool to. The biological network modeling is an important tool to understand. Biological network modeling is an important tool to understand the complex. Biological network modeling is an important tool to understand the complex. Biological network modeling is an important tool to understand the complex. Biological network modeling is an important tool to understand the complex. Biological network modeling is an important tool to understand the complex. Biological network modeling is an important tool to understand the complex. Biological network modeling is an important tool to understand the complex. Biological network modeling is an important tool to understand the complex. Biological network modeling is an important tool to understand the complex. Biological network modeling is an important tool to understand the complex. Biological network modeling is an important tool to understand the complex. Biological network modeling is an important tool to understand the complex. Biological network modeling is an important tool to understand the complex. Biological network modeling is an important tool to understand the complex. Biological network modeling is an important tool to understand the complex. Biological network modeling is an important tool to understand the complex. Biological network modeling is an important tool to understand the complex. Biological network modeling is an important tool to understand the complex\n"
     ]
    }
   ],
   "source": [
    "# run a test prediction\n",
    "outputs = pipeline(\n",
    "    text,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
